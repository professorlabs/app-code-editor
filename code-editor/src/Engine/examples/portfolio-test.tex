\documentclass{portfolio}
\usepackage[utf8]{inputenc}

\title{Dr. Sarah Johnson}
\author{Machine Learning Research Scientist}
\date{2024}

\begin{document}

% Navigation configuration
\navlogo{profile_photo.png}
\nabbar{Research, Publications, Projects, Contact}




\section{Research Overview}

I am a \textbf{machine learning researcher} specializing in \textbf{deep learning} and \textbf{natural language processing}. My work focuses on developing novel architectures for large language models and their applications in scientific discovery.

\subsection{Current Research Focus}

\begin{itemize}
    \item Efficient training methods for large-scale language models
    \item Neural architecture search and automated model design
    \item Applications of AI in healthcare and drug discovery
    \item Responsible AI development and ethical considerations
\end{itemize}

\section{Selected Publications}

\subsection{Journal Articles}

\begin{itemize}
    \item \textbf{Johnson, S.}, et al. (2024). "Efficient Training of Large Language Models via Gradient Sparsification." \textit{Nature Machine Intelligence}, 6(3), 234-245.
    
    \item Chen, L., \textbf{Johnson, S.}, \& Kumar, R. (2024). "Neural Architecture Search for Scientific Computing." \textit{Journal of Machine Learning Research}, 25(1), 1-28.
    
    \item \textbf{Johnson, S.} (2023). "Scalable Transformers for Protein Structure Prediction." \textit{Science Advances}, 9(15), eabc1234.
\end{itemize}

\subsection{Conference Papers}

\begin{itemize}
    \item \textbf{Johnson, S.}, Zhang, M., \& Lee, K. (2024). "AutoML-Zero: Evolving Machine Learning Algorithms from Scratch." In \textit{Proceedings of ICML 2024} (pp. 5678-5692).
    
    \item Wang, T., \textbf{Johnson, S.}, et al. (2024). "Federated Learning for Medical Imaging: Privacy-Preserving Collaborative Diagnostics." In \textit{Proceedings of NeurIPS 2024}.
    
    \item \textbf{Johnson, S.} (2023). "Attention Is Not All You Need: A Critical Analysis." In \textit{Proceedings of ICLR 2023}.
\end{itemize}

\section{Research Projects}

\subsection{AI for Drug Discovery}

Leading a multidisciplinary team developing novel machine learning approaches for accelerated drug discovery. Our work has identified three promising compounds for Alzheimer's treatment currently in preclinical trials.

\subsection{Scalable Training Infrastructure}

Developing distributed training algorithms that reduce the computational cost of training large language models by 40\% while maintaining performance. This work is being adopted by major AI research labs.

\section{Academic Background}

\begin{itemize}
    \item \textbf{Ph.D. in Computer Science} - Stanford University (2018-2022)
    \begin{itemize}
        \item Advisor: Professor Andrew Ng
        \item Thesis: "Efficient Methods for Training Large-Scale Neural Networks"
    \end{itemize}
    
    \item \textbf{M.S. in Artificial Intelligence} - MIT (2016-2018)
    \begin{itemize}
        \item Focus: Deep Learning and Natural Language Processing
        \item Thesis: "Neural Architecture Search with Evolutionary Algorithms"
    \end{itemize}
    
    \item \textbf{B.S. in Computer Science and Mathematics} - UC Berkeley (2012-2016)
    \begin{itemize}
        \item Summa Cum Laude, GPA: 3.9/4.0
        \item Chancellor's Scholar, ACM International Collegiate Programming Contest Finalist
    \end{itemize}
\end{itemize}

\section{Awards and Honors}

\begin{itemize}
    \item NSF CAREER Award (2024)
    \item MIT Technology Review's 35 Innovators Under 35 (2023)
    \item Best Paper Award, ICML 2024
    \item Google PhD Fellowship (2019-2022)
    \item NSF Graduate Research Fellowship (2018-2021)
\end{itemize}

\section{Professional Activities}

\subsection{Academic Service}

\begin{itemize}
    \item Senior Program Committee: ICML 2024, NeurIPS 2024
    \item Program Committee: ICLR 2023, AAAI 2023
    \item Reviewer: Nature Machine Intelligence, JMLR, PAMI
\end{itemize}

\subsection{Industry Collaboration}

\begin{itemize}
    \item Research Consultant, OpenAI (2023-present)
    \item Visiting Researcher, Google Brain (Summer 2022)
    \item Research Intern, DeepMind (Summer 2021)
\end{itemize}

\section{Contact Information}

\begin{itemize}
    \item \textbf{Email}: sarah.johnson@stanford.edu
    \item \textbf{Office}: Gates Computer Science Building, Room 250
    \item \textbf{Lab}: Stanford AI Lab
    \item \textbf{Twitter}: @drsarahjohnson
    \item \textbf{GitHub}: github.com/sarahjohnson
    \item \textbf{Google Scholar}: Available upon request
\end{itemize}

\end{document}